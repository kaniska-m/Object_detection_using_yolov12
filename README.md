# ğŸ… Object Detection Using YOLOv12-Nano on Raspberry Pi

This repository showcases a **lightweight, real-time object detection system** using the **YOLOv12-Nano** model, trained for tomato ripeness classification and deployed on a **Raspberry Pi**. The project demonstrates efficient AI inference on edge devices for smart agriculture applications.

---

## ğŸš€ Features

- Real-time object detection using YOLOv12-Nano.
- Optimized model deployment using **TFLite** for Raspberry Pi.
- Custom dataset with **augmented training** for robust detection.
- Python-based **Flask web UI** for live streaming detection output.
- Low-latency performance for edge computing applications.

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ yolov12-nano.tflite          # TFLite optimized model
â”‚   â””â”€â”€ labelmap.txt                 # Class labels
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ ...                          # Image dataset (optional link to external source)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ detect.py                    # Real-time detection script
â”‚   â””â”€â”€ utils.py                     # Helper functions
â”œâ”€â”€ web_ui/
â”‚   â”œâ”€â”€ app.py                       # Flask-based UI for live streaming
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html               # Web interface
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Requirements

Install the required dependencies on Raspberry Pi (Python 3.7+ recommended):

```bash
pip install -r requirements.txt
```

Additional dependencies:
- `opencv-python`
- `tensorflow==2.10.0` *(use lite version for Pi)*
- `flask`
- `imutils`

---

## ğŸ“¸ Dataset and Preprocessing

- 482 real-world tomato images collected and annotated (YOLO format).
- Augmentation applied:
  - Rotation
  - Brightness variation
  - Gaussian blur
- Final dataset size: **1930 images**
- Image resolution: **640 Ã— 640**
- Labels: `["unripe", "semi-ripe", "ripe"]`

[Click here to view dataset (optional link)](https://example.com)

---

## ğŸ§  Model Training

Training was performed on Google Colab with GPU acceleration using the **YOLOv12-Nano** architecture.

### Training Script (Colab):

```python
!python train.py \
  --data dataset.yaml \
  --cfg yolov12-nano.yaml \
  --weights '' \
  --epochs 100 \
  --img 640
```

Post-training, the model was **quantized** and exported to **TensorFlow Lite (TFLite)** using:

```python
converter = tf.lite.TFLiteConverter.from_saved_model('best_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
```

---

## ğŸ§ª Live Detection on Raspberry Pi

### Run the detection script:

```bash
python3 scripts/detect.py --model model/yolov12-nano.tflite --labels model/labelmap.txt --camera 0
```

### Optional: Run with Flask UI:

```bash
cd web_ui
python3 app.py
```

Open your browser at `http://<raspberry_pi_ip>:5000` to view live detection.

---

## ğŸ“Š Performance

| Metric       | Value                    |
|--------------|---------------------------|
| FPS (avg)    | ~10 FPS (Raspberry Pi 4)  |
| Model Size   | < 5 MB (TFLite)           |
| Accuracy     | 91.2% mAP@0.5             |

---

## ğŸ“Œ Applications

- Smart agricultural harvesting
- Tomato ripeness sorting
- Autonomous robotic arms for crop selection

---

## ğŸ™Œ Acknowledgments

- [YOLOv12 authors](https://github.com/YOLOv12)
- [TensorFlow Lite](https://www.tensorflow.org/lite/)
- [OpenCV](https://opencv.org/)
- [Flask](https://flask.palletsprojects.com/)

---

## ğŸ“ƒ License

This project is licensed under the MIT License. See `LICENSE` for more information.
